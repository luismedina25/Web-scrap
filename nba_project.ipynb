{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Basketball Reference Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the website Basketball-reference.com in order to scrap data of the players from multiple different seasons. This website provides clean sport data, thus making it easy to scrape the data and create my own database from the data gathered on the website.\n",
    "\n",
    "Now to import all the libraries we would need in order to begin web scarping the data from the website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create the function to gather data from the website. It will take in the year we want for that season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to gather data from the web parameter is the year\n",
    "def scrape_nba_data(years):\n",
    "    url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\".format(years)\n",
    "\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "        soup = BeautifulSoup(html, features=\"lxml\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "    \n",
    "    headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
    "    headers.remove('Rk')\n",
    "\n",
    "    rows = soup.findAll('tr')[1:]\n",
    "    rows_data = [[td.getText() for td in rows[i].findAll('td')] \n",
    "                    for i in range(len(rows))]\n",
    "    \n",
    "    df = pd.DataFrame(rows_data, columns=headers)\n",
    "    df.dropna(axis = 0, inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Replace empty string with '0'\n",
    "    df.replace('', '0', inplace=True)   \n",
    "\n",
    "    # convert numeric columns to float\n",
    "    numeric_columns = df.columns.drop(['Player', 'Pos', 'Tm'])\n",
    "    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we created the function to be able to gather data now we can get data from all the different seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
